{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow torch opencv-python pandas scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "# Create an EasyOCR Reader instance\n",
    "# Specify the languages to use (e.g., ['en'] for English)\n",
    "# Setting gpu=True will use the GPU if available, otherwise it defaults to CPU\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "print(\"EasyOCR reader loaded successfully with English language model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the test CSV file\n",
    "test_csv_file_path = 'extracted_archive/testdata.csv'\n",
    "\n",
    "# Check if the CSV file exists\n",
    "if not os.path.exists(test_csv_file_path):\n",
    "    print(f\"Error: The file {test_csv_file_path} was not found.\")\n",
    "else:\n",
    "    try:\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        # Assuming the file is comma-separated and has a header row\n",
    "        # We'll explicitly name the columns as they might not be consistently named\n",
    "        test_df = pd.read_csv(test_csv_file_path, sep=',', header=0, names=['ImgName', 'GroundTruth', 'smallLexi', 'mediumLexi'])\n",
    "\n",
    "        # --- Filter DataFrame to include only 'test' images ---\n",
    "        initial_rows_test = len(test_df)\n",
    "        test_df = test_df[test_df['ImgName'].str.startswith('test/')]\n",
    "        filtered_rows_test = len(test_df)\n",
    "        print(f\"Filtered test data: Kept {filtered_rows_test} rows starting with 'test/' out of {initial_rows_test}.\")\n",
    "        # --- End filtering ---\n",
    "\n",
    "\n",
    "        # Print the first few rows of the DataFrame\n",
    "        print(\"Test CSV data loaded successfully:\")\n",
    "        display(test_df.head())\n",
    "\n",
    "        # Print DataFrame information\n",
    "        print(\"\\nTest DataFrame Info:\")\n",
    "        test_df.info()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the test CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume resize_image, normalize_pixels, and grayscale_image functions are already defined\n",
    "# Assume test_df is loaded from the previous step\n",
    "\n",
    "# 1. Create empty lists\n",
    "processed_test_images = []\n",
    "original_test_labels = []\n",
    "\n",
    "# Correct Base directory for images - same as training data\n",
    "base_image_dir = 'extracted_archive/IIIT5K-Word_V3.0/IIIT5K'\n",
    "\n",
    "# Target size for resizing (same as training)\n",
    "target_size = (128, 32) # (width, height)\n",
    "\n",
    "# Check if test_df exists and is not empty before proceeding\n",
    "if 'test_df' in locals() and not test_df.empty:\n",
    "    # 2. Iterate through each row of the test_df DataFrame\n",
    "    for index, row in test_df.iterrows():\n",
    "        # 3. Get image path and text label\n",
    "        image_path_relative = row['ImgName']\n",
    "        text_label = row['GroundTruth']\n",
    "\n",
    "        # Construct the full image path\n",
    "        full_image_path = os.path.join(base_image_dir, image_path_relative)\n",
    "\n",
    "        # 4. Check if the image file exists\n",
    "        if os.path.exists(full_image_path):\n",
    "            # 5. Read the image\n",
    "            img = cv2.imread(full_image_path)\n",
    "\n",
    "            # 6. If the image is successfully loaded (not None)\n",
    "            if img is not None:\n",
    "                # Apply preprocessing steps\n",
    "                gray_img = grayscale_image(img)\n",
    "                resized_img = resize_image(gray_img, target_size)\n",
    "                normalized_img = normalize_pixels(resized_img) # This is float32\n",
    "\n",
    "                # 7. Append the preprocessed image (float32) to the list\n",
    "                processed_test_images.append(normalized_img)\n",
    "\n",
    "                # 8. Append the original text label\n",
    "                original_test_labels.append(text_label)\n",
    "            else:\n",
    "                # 9. If image cannot be loaded, print warning and skip\n",
    "                print(f\"Warning: Could not load image file: {full_image_path}\")\n",
    "        else:\n",
    "            # 9. If image file not found, print warning and skip\n",
    "            print(f\"Warning: Image file not found: {full_image_path}\")\n",
    "\n",
    "    # 10. Convert the processed_test_images list into a NumPy array\n",
    "    processed_test_images = np.array(processed_test_images)\n",
    "\n",
    "    # 11. Convert the original_test_labels list into a pandas Series or NumPy array\n",
    "    original_test_labels = pd.Series(original_test_labels)\n",
    "\n",
    "    # 12. Print the shape and length to verify\n",
    "    print(\"Preprocessing of test images complete.\")\n",
    "    print(\"Shape of processed_test_images array:\", processed_test_images.shape)\n",
    "    print(\"Length of original_test_labels list:\", len(original_test_labels))\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame 'test_df' not found or is empty. Please run the cell to load the test CSV first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "# Download the necessary NLTK data\n",
    "try:\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    print(\"NLTK data ('averaged_perceptron_tagger', 'punkt') downloaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK data: {e}\")\n",
    "\n",
    "\n",
    "def calculate_cer(ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Calculates the Character Error Rate (CER) between two strings.\n",
    "\n",
    "    Args:\n",
    "        ground_truth: The ground truth string.\n",
    "        prediction: The predicted string.\n",
    "\n",
    "    Returns:\n",
    "        The Character Error Rate (float). Returns 0 if ground_truth is empty.\n",
    "    \"\"\"\n",
    "    # Handle empty ground truth to avoid division by zero\n",
    "    if len(ground_truth) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate Levenshtein distance (character-level)\n",
    "    levenstein_dist = edit_distance(ground_truth, prediction)\n",
    "\n",
    "    # CER is Levenshtein distance divided by the length of the ground truth\n",
    "    cer = levenstein_dist / len(ground_truth)\n",
    "    return cer\n",
    "\n",
    "def calculate_wer(ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Calculates the Word Error Rate (WER) between two strings.\n",
    "\n",
    "    Args:\n",
    "        ground_truth: The ground truth string.\n",
    "        prediction: The predicted string.\n",
    "\n",
    "    Returns:\n",
    "        The Word Error Rate (float). Returns 0 if ground_truth is empty (after splitting into words).\n",
    "    \"\"\"\n",
    "    # Split strings into words\n",
    "    # Use a simple split by space for word tokenization\n",
    "    ground_truth_words = ground_truth.split()\n",
    "    prediction_words = prediction.split()\n",
    "\n",
    "    # Handle empty ground truth word list to avoid division by zero\n",
    "    if len(ground_truth_words) == 0:\n",
    "        # If ground truth is an empty string, WER should arguably be 0\n",
    "        # If prediction is also empty, error is 0. If prediction is not empty, error is high.\n",
    "        # A common approach for empty reference is to return 0 if hypothesis is also empty, else inf or 1.\n",
    "        # Let's return 0 for consistency with CER on empty string.\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "    # Calculate Levenshtein distance (word-level)\n",
    "    # edit_distance can work on lists\n",
    "    levenstein_dist = edit_distance(ground_truth_words, prediction_words)\n",
    "\n",
    "\n",
    "    # WER is Levenshtein distance divided by the number of words in the ground truth\n",
    "    wer = levenstein_dist / len(ground_truth_words)\n",
    "    return wer\n",
    "\n",
    "print(\"Character Error Rate (CER) and Word Error Rate (WER) calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Assume reader is loaded from the previous cell\n",
    "# Assume test_df is available from previous steps (loaded testdata.csv)\n",
    "# Assume processed_test_images is available from previous steps (preprocessed test images)\n",
    "# Assume calculate_cer and calculate_wer functions are defined (cell kOLluGXQ8bLg)\n",
    "\n",
    "# Check if necessary variables are available\n",
    "if 'reader' in locals() and 'test_df' in locals() and not test_df.empty and 'processed_test_images' in locals() and processed_test_images.size > 0:\n",
    "\n",
    "    print(\"Starting text recognition and evaluation using EasyOCR...\")\n",
    "\n",
    "    # Initialize empty lists to store the calculated CER and WER\n",
    "    all_easyocr_cer = []\n",
    "    all_easyocr_wer = []\n",
    "\n",
    "    total_samples = processed_test_images.shape[0]\n",
    "    print(f\"Processing {total_samples} test samples with EasyOCR...\")\n",
    "\n",
    "    # Iterate through the preprocessed test images\n",
    "    for i in range(total_samples):\n",
    "        # Get the preprocessed image (NumPy array)\n",
    "        # EasyOCR's readtext function expects a NumPy array or image file path\n",
    "        image_for_easyocr = processed_test_images[i] # This is already preprocessed (grayscale, resized, normalized float32)\n",
    "\n",
    "        # EasyOCR works best with original images or images in standard formats (like uint8)\n",
    "        # Since processed_test_images is float32 [0, 1], let's convert it back to uint8 [0, 255]\n",
    "        # and ensure it's in grayscale format if needed by EasyOCR.\n",
    "        # Based on EasyOCR documentation, it can handle grayscale or color.\n",
    "        # Let's convert back to uint8.\n",
    "        image_for_easyocr_uint8 = (image_for_easyocr * 255).astype(np.uint8)\n",
    "\n",
    "        # EasyOCR expects shape (height, width) or (height, width, channels).\n",
    "        # processed_test_images has shape (num_samples, height, width) after preprocessing.\n",
    "        # When we select processed_test_images[i], it has shape (height, width).\n",
    "        # This should be suitable for EasyOCR's readtext.\n",
    "\n",
    "        # Perform text recognition using EasyOCR's readtext\n",
    "        # The result is a list of tuples: (bbox, text, confidence)\n",
    "        easyocr_results = reader.readtext(image_for_easyocr_uint8, detail=0) # detail=0 returns only the text\n",
    "\n",
    "        # Combine the recognized text from all detected regions (EasyOCR does detection internally)\n",
    "        # Join the recognized text strings with a space\n",
    "        recognized_text = \" \".join(easyocr_results)\n",
    "\n",
    "        # Get the corresponding ground truth label from the original test_df\n",
    "        # Assume original_test_labels is available from cell 7dfe8ff3\n",
    "        ground_truth_label = test_df.iloc[i]['GroundTruth']\n",
    "\n",
    "\n",
    "        # Convert ground truth and recognized text to lowercase for case-insensitive evaluation\n",
    "        ground_truth_lower = ground_truth_label.lower()\n",
    "        recognized_text_lower = recognized_text.lower()\n",
    "\n",
    "        # Calculate CER and WER\n",
    "        cer = calculate_cer(ground_truth_lower, recognized_text_lower)\n",
    "        wer = calculate_wer(ground_truth_lower, recognized_text_lower)\n",
    "\n",
    "        # Append to lists\n",
    "        all_easyocr_cer.append(cer)\n",
    "        all_easyocr_wer.append(wer)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{total_samples} samples with EasyOCR.\")\n",
    "\n",
    "\n",
    "    # Calculate the average CER and WER\n",
    "    average_easyocr_cer = np.mean(all_easyocr_cer)\n",
    "    average_easyocr_wer = np.mean(all_easyocr_wer)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\n--- EasyOCR Evaluation Results ---\")\n",
    "    print(f\"Average Character Error Rate (CER): {average_easyocr_cer:.4f}\")\n",
    "    print(f\"Average Word Error Rate (WER): {average_easyocr_wer:.4f}\")\n",
    "\n",
    "    print(\"EasyOCR evaluation completed.\")\n",
    "\n",
    "    # --- Visualize Predictions on Random Samples using EasyOCR ---\n",
    "    # Check if test_df exists and is not empty for visualization\n",
    "    if 'test_df' in locals() and not test_df.empty:\n",
    "        # Get a list of all possible indices in the test DataFrame\n",
    "        all_indices = list(test_df.index)\n",
    "\n",
    "        # Number of samples to visualize\n",
    "        num_samples_to_visualize = 10 # You can change this number\n",
    "\n",
    "        # Select random indices for visualization\n",
    "        if len(all_indices) >= num_samples_to_visualize:\n",
    "            sample_indices = random.sample(all_indices, num_samples_to_visualize)\n",
    "        else:\n",
    "            # If not enough samples, visualize all available\n",
    "            sample_indices = all_indices\n",
    "            num_samples_to_visualize = len(all_indices) # Update the number to visualize\n",
    "\n",
    "        print(f\"\\nVisualizing EasyOCR predictions for {num_samples_to_visualize} random samples from the test set.\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "\n",
    "        # Process and Visualize Samples\n",
    "        # Need to load the original image for visualization with bounding boxes\n",
    "        base_image_dir = 'extracted_archive/IIIT5K-Word_V3.0/IIIT5K' # Base directory for original images\n",
    "\n",
    "        for i in sample_indices:\n",
    "            # Get the image path and ground truth label for the selected index\n",
    "            row = test_df.iloc[i]\n",
    "            image_path_relative = row['ImgName']\n",
    "            ground_truth_label = row['GroundTruth']\n",
    "\n",
    "            # Construct the full image path to load the original image\n",
    "            full_image_path = os.path.join(base_image_dir, image_path_relative)\n",
    "\n",
    "            # Load the original image\n",
    "            original_image = cv2.imread(full_image_path)\n",
    "\n",
    "            if original_image is not None:\n",
    "                # Use EasyOCR's readtext with detail=1 to get bounding boxes for visualization\n",
    "                easyocr_results_detail = reader.readtext(original_image, detail=1)\n",
    "\n",
    "                # Extract recognized text and draw bounding boxes on the original image\n",
    "                recognized_texts_for_viz = []\n",
    "                img_with_boxes = original_image.copy()\n",
    "\n",
    "                for (bbox, text, prob) in easyocr_results_detail:\n",
    "                    recognized_texts_for_viz.append(text)\n",
    "                    # Draw bounding box (bbox is a list of 4 points)\n",
    "                    # Convert the bbox points to integer tuples\n",
    "                    points = np.array(bbox, dtype=np.int32)\n",
    "                    cv2.polylines(img_with_boxes, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "                    # Optional: Put text near the bounding box\n",
    "                    # cv2.putText(img_with_boxes, text, (points[0][0], points[0][1] - 10),\n",
    "                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "                # Combine recognized text for display\n",
    "                combined_recognized_text_for_viz = \" \".join(recognized_texts_for_viz)\n",
    "\n",
    "\n",
    "                # --- Display Results ---\n",
    "                print(f\"Sample Index: {i}\")\n",
    "                print(f\"Ground Truth: {ground_truth_label}\")\n",
    "                print(f\"EasyOCR Prediction: {combined_recognized_text_for_viz}\")\n",
    "\n",
    "                # Display the original image with bounding boxes (resized for consistent size)\n",
    "                # Adjust the resize target based on the original image dimensions for better aspect ratio\n",
    "                display_width = 300\n",
    "                display_height = int(img_with_boxes.shape[0] * (display_width / img_with_boxes.shape[1]))\n",
    "                display_img_with_boxes = cv2.resize(img_with_boxes, (display_width, display_height))\n",
    "                cv2_imshow(display_img_with_boxes)\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: Could not load image file for visualization: {full_image_path}\")\n",
    "\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        print(\"EasyOCR visualization complete.\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nDataFrame 'test_df' not found or is empty. Skipping visualization.\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Necessary variables for EasyOCR evaluation not found. Please run previous cells to load data, preprocess, and load the EasyOCR reader.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
